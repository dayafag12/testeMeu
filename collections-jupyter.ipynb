{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Collections - Jupyter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "YEAR = '2022'\n",
    "MONTH = 'junho'\n",
    "CAMPAIGN = 'spike'\n",
    "CAMPAIGN_ENTRY_DATE = '2022-06-12'\n",
    "CAMPAIGN_EXIT_DATE = '2022-06-12'\n",
    "CLUSTER_DELIVERY_FOLDER_ID = '1aHhaVTzJAOKB8bL6Urp4z4J8x0k535Gi'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import re\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "import gspread\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from gspread_dataframe import set_with_dataframe\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Authentication with Google Drive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sea Group\\anaconda3\\anaconda\\lib\\site-packages\\oauth2client\\_helpers.py:255: UserWarning: Cannot access ../credentials/mycreds.txt: No such file or directory\n",
      "  warnings.warn(_MISSING_FILE_MESSAGE.format(filename))\n"
     ]
    }
   ],
   "source": [
    "gauth = GoogleAuth()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "gauth.LoadCredentialsFile('../credentials/mycreds.txt')\n",
    "if gauth.credentials is None:\n",
    "    gauth.LocalWebserverAuth()\n",
    "elif gauth.access_token_expired:\n",
    "    os.remove('../credentials/mycreds.txt')\n",
    "    gauth.LocalWebserverAuth()\n",
    "else:\n",
    "    gauth.Authorize()\n",
    "\n",
    "gauth.SaveCredentialsFile('../credentials/mycreds.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "### gspread functions ###\n",
    "#########################\n",
    "\n",
    "# TODO: insert your own credentials file with help of gspread documentation. (https://docs.gspread.org/en/latest/oauth2.html)\n",
    "\n",
    "def gspread_start(service_account='../credentials/client_secrets.json'):\n",
    "    \"\"\"Start gspread authentication.\n",
    "\n",
    "    Args:\n",
    "        service_account (str, optional): Path of the Google Cloud service_account json.\n",
    "        Defaults to '../credentials/gsheets.json'.\n",
    "\n",
    "    Returns:\n",
    "        gc: gc is a connection object with the Google Sheets API.\n",
    "    \"\"\"\n",
    "    scope = ['https://spreadsheets.google.com/feeds']\n",
    "    #credentials = Credentials.from_service_account_file(service_account, scopes=scope)\n",
    "    gc = gspread.oauth(credentials_filename = \"../credentials/credentials.json\")\n",
    "    return gc\n",
    "\n",
    "\n",
    "def get_spreadsheet_dataframe(spreadsheet_key, worksheet):\n",
    "    \"\"\"Stablish the gspread connection and return the dataframe of the spreadsheet.\n",
    "\n",
    "    Args:\n",
    "        spreadsheet_key (string): The ID of the Google Spreadsheet\n",
    "        worksheet (string): The title of the worksheet\n",
    "\n",
    "    Returns:\n",
    "        Dataframe: Returns a dataframe of the spreadsheet.\n",
    "    \"\"\"\n",
    "    book = gspread_start().open_by_key(spreadsheet_key)\n",
    "    sheet = book.worksheet(worksheet)\n",
    "    table = sheet.get_all_values()\n",
    "    return pd.DataFrame(table[1:], columns = table[0])\n",
    "\n",
    "\n",
    "#########################\n",
    "##### convert list ######\n",
    "#########################\n",
    "\n",
    "# We use this function to convert the category column in Parameters file.\n",
    "def ConvertList(strConv):\n",
    "    \"\"\"Convert a string list (example: \"apple, fruit, grape\") into an actual Python list.\n",
    "\n",
    "    Args:\n",
    "        strConv (string): String you want to convert.\n",
    "\n",
    "    Returns:\n",
    "        list: Returns a list with all the elements separated by comma.\n",
    "    \"\"\"\n",
    "    list_in = list(strConv.split(\",\"))\n",
    "    return list_in\n",
    "\n",
    "\n",
    "#########################\n",
    "###### sort by cat ######\n",
    "#########################\n",
    "\n",
    "def sort_by_cat(df,cat):\n",
    "    \"\"\"Algorithm that sorts the elements of a collection according to their categories.\n",
    "\n",
    "    Args:\n",
    "        df (Dataframe): The dataframe you want to sort, in this case, the collection.\n",
    "        cat (Dataframe.column): The column of the dataframe to sort by, in this case, the category.\n",
    "\n",
    "    Returns:\n",
    "        Dataframe: Returns the dataframe sorted by category.\n",
    "    \"\"\"\n",
    "    n = df.shape[0]\n",
    "    df_new = pd.DataFrame()\n",
    "    for x in range(n):\n",
    "        for i in df[cat].unique():\n",
    "            df_apoio = df.loc[df[cat]==i]\n",
    "            if x <= (df_apoio.shape[0]-1):\n",
    "                df_apoio = df_apoio.sort_values('score',ascending = False).reset_index()\n",
    "                df_apoio = df_apoio.iloc[[x]]                \n",
    "                df_new = pd.concat([df_new, df_apoio])\n",
    "            else: pass\n",
    "    return df_new\n",
    "\n",
    "#########################\n",
    "#### score functions ####\n",
    "#########################\n",
    "\n",
    "\n",
    "# TODO: change score categories\n",
    "def classifier(df):\n",
    "    \"\"\"Algorithm to classify and define score for every element of a collection.\n",
    "\n",
    "    Args:\n",
    "        df (Dataframe): The collection dataframe.\n",
    "\n",
    "    Returns:\n",
    "        Dataframe: Returns the dataframe, with the score and sorted by the score.\n",
    "    \"\"\"\n",
    "    n = df.shape[0]\n",
    "    lista = []\n",
    "    for value in range(n):\n",
    "        lista.append(scorer.score(df.iloc[value]))\n",
    "    df['score'] = lista\n",
    "    df = df.sort_values('score',ascending = False)\n",
    "    return df\n",
    "\n",
    "\n",
    "class BaseScorer(object):\n",
    "    \"\"\"Class for handling the process of scoring.\n",
    "\n",
    "    Args:\n",
    "        object (_type_): _description_\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self._next_scorer = None\n",
    "\n",
    "    def set_next(self, scorer):\n",
    "        self._next_scorer = scorer\n",
    "\n",
    "        return scorer\n",
    "\n",
    "    def _call_next(self, collection, score):\n",
    "\n",
    "        if self._next_scorer is None:\n",
    "            return score\n",
    "\n",
    "        return self._next_scorer.score(collection, score)\n",
    "\n",
    "    def score(self, collection, score=0):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @staticmethod\n",
    "    def chain(scorers):\n",
    "        reduce(lambda x, y: x.set_next(y), scorers)\n",
    "\n",
    "        return scorers[0]\n",
    "\n",
    "\n",
    "class sales(BaseScorer):\n",
    "    \"\"\"Class for handling the sales score.\"\n",
    "\n",
    "    Args:\n",
    "        BaseScorer (_type_): _description_\n",
    "    \"\"\"\n",
    "\n",
    "    def score(self, collection, score=0):\n",
    "        for category in dfs_para.keys():\n",
    "            n = (np.where(~np.isnan(dfs_para[str(category)]['Score Vendas'])))\n",
    "            n = n[0].tolist()            \n",
    "            if (category =='Bags') & (collection.main_category in (['Bags', 'Jewelry & Watches', 'Fashion Accessories'])):\n",
    "                for i in n:\n",
    "                    if i is not n[-1]:\n",
    "                        if (collection.gross_orders >= dfs_para[str(category)]['Valor Vendas'][i]) & (collection.gross_orders < dfs_para[str(category)]['Valor Vendas'][i+1]):\n",
    "                            score = score + dfs_para[str(category)]['Score Vendas'][i]*dfs_para[str(category)]['Peso Venda'][0]\n",
    "\n",
    "                    elif (collection.gross_orders >= dfs_para[str(category)]['Valor Vendas'][i]):\n",
    "                            score = score + dfs_para[str(category)]['Score Vendas'][i]*dfs_para[str(category)]['Peso Venda'][0] \n",
    "\n",
    "                return self._call_next(collection, score)\n",
    "\n",
    "            if (category =='Clothes') & (collection.main_category in (['Women Clothes', 'Men Clothes'])) & (collection.sub_category not in (['Underwear & Sleepwear', 'Socks'])):\n",
    "                for i in n:\n",
    "                    if i is not n[-1]:\n",
    "                        if (collection.gross_orders >= dfs_para[str(category)]['Valor Vendas'][i]) & (collection.gross_orders < dfs_para[str(category)]['Valor Vendas'][i+1]):\n",
    "                            score = score + dfs_para[str(category)]['Score Vendas'][i]*dfs_para[str(category)]['Peso Venda'][0]\n",
    "\n",
    "                    elif (collection.gross_orders >= dfs_para[str(category)]['Valor Vendas'][i]):\n",
    "                            score = score + dfs_para[str(category)]['Score Vendas'][i]*dfs_para[str(category)]['Peso Venda'][0] \n",
    "\n",
    "                return self._call_next(collection, score)\n",
    "\n",
    "            if (category =='Underwear') & (collection.sub_category in (['Underwear & Sleepwear', 'Socks'])):\n",
    "                for i in n:\n",
    "                    if i is not n[-1]:\n",
    "                        if (collection.gross_orders >= dfs_para[str(category)]['Valor Vendas'][i]) & (collection.gross_orders < dfs_para[str(category)]['Valor Vendas'][i+1]):\n",
    "                            score = score + dfs_para[str(category)]['Score Vendas'][i]*dfs_para[str(category)]['Peso Venda'][0]\n",
    "\n",
    "                    elif (collection.gross_orders >= dfs_para[str(category)]['Valor Vendas'][i]):\n",
    "                            score = score + dfs_para[str(category)]['Score Vendas'][i]*dfs_para[str(category)]['Peso Venda'][0] \n",
    "\n",
    "                return self._call_next(collection, score)\n",
    "\n",
    "            if (category =='Shoes') & (collection.main_category == 'Shoes'):\n",
    "                for i in n:\n",
    "                    if i is not n[-1]:\n",
    "                        if (collection.gross_orders >= dfs_para[str(category)]['Valor Vendas'][i]) & (collection.gross_orders < dfs_para[str(category)]['Valor Vendas'][i+1]):\n",
    "                            score = score + dfs_para[str(category)]['Score Vendas'][i]*dfs_para[str(category)]['Peso Venda'][0]\n",
    "\n",
    "                    elif (collection.gross_orders >= dfs_para[str(category)]['Valor Vendas'][i]):\n",
    "                            score = score + dfs_para[str(category)]['Score Vendas'][i]*dfs_para[str(category)]['Peso Venda'][0] \n",
    "\n",
    "                return self._call_next(collection, score)\n",
    "            \n",
    "            \n",
    "class rating(BaseScorer):\n",
    "    \"\"\"Class for handling the rating score.\n",
    "\n",
    "    Args:\n",
    "        BaseScorer (_type_): _description_\n",
    "    \"\"\"\n",
    "\n",
    "    def score(self, collection, score=0):\n",
    "        for category in dfs_para.keys():\n",
    "            n = (np.where(~np.isnan(dfs_para[str(category)]['Score Rating'])))\n",
    "            n = n[0].tolist()            \n",
    "            if (category =='Bags') & (collection.main_category in (['Bags', 'Jewelry & Watches', 'Fashion Accessories'])):\n",
    "                for i in n:\n",
    "                    if i is not n[-1]:\n",
    "                        if (collection.Rxq >= dfs_para[str(category)]['Valor Rating'][i]) & (collection.Rxq < dfs_para[str(category)]['Valor Rating'][i+1]):\n",
    "                            score = score + dfs_para[str(category)]['Score Rating'][i]*dfs_para[str(category)]['Peso Rating'][0]\n",
    "\n",
    "                    elif (collection.Rxq >= dfs_para[str(category)]['Valor Rating'][i]):\n",
    "                            score = score + dfs_para[str(category)]['Score Rating'][i]*dfs_para[str(category)]['Peso Rating'][0] \n",
    "\n",
    "                return self._call_next(collection, score)\n",
    "\n",
    "            if (category =='Clothes') & (collection.main_category in (['Women Clothes', 'Men Clothes'])) & (collection.sub_category not in (['Underwear & Sleepwear', 'Socks'])):\n",
    "                for i in n:\n",
    "                    if i is not n[-1]:\n",
    "                        if (collection.Rxq >= dfs_para[str(category)]['Valor Rating'][i]) & (collection.Rxq < dfs_para[str(category)]['Valor Rating'][i+1]):\n",
    "                            score = score + dfs_para[str(category)]['Score Rating'][i]*dfs_para[str(category)]['Peso Rating'][0]\n",
    "\n",
    "                    elif (collection.Rxq >= dfs_para[str(category)]['Valor Rating'][i]):\n",
    "                            score = score + dfs_para[str(category)]['Score Rating'][i]*dfs_para[str(category)]['Peso Rating'][0] \n",
    "\n",
    "                return self._call_next(collection, score)\n",
    "\n",
    "            if (category =='Underwear') & (collection.sub_category in (['Underwear & Sleepwear', 'Socks'])):\n",
    "                for i in n:\n",
    "                    if i is not n[-1]:\n",
    "                        if (collection.Rxq >= dfs_para[str(category)]['Valor Rating'][i]) & (collection.Rxq < dfs_para[str(category)]['Valor Rating'][i+1]):\n",
    "                            score = score + dfs_para[str(category)]['Score Rating'][i]*dfs_para[str(category)]['Peso Rating'][0]\n",
    "\n",
    "                    elif (collection.Rxq >= dfs_para[str(category)]['Valor Rating'][i]):\n",
    "                            score = score + dfs_para[str(category)]['Score Rating'][i]*dfs_para[str(category)]['Peso Rating'][0]  \n",
    "\n",
    "                return self._call_next(collection, score)\n",
    "\n",
    "            if (category =='Shoes') & (collection.main_category == 'Shoes'):\n",
    "                for i in n:\n",
    "                    if i is not n[-1]:\n",
    "                        if (collection.Rxq >= dfs_para[str(category)]['Valor Rating'][i]) & (collection.Rxq < dfs_para[str(category)]['Valor Rating'][i+1]):\n",
    "                            score = score + dfs_para[str(category)]['Score Rating'][i]*dfs_para[str(category)]['Peso Rating'][0]\n",
    "\n",
    "                    elif (collection.Rxq >= dfs_para[str(category)]['Valor Rating'][i]):\n",
    "                            score = score + dfs_para[str(category)]['Score Rating'][i]*dfs_para[str(category)]['Peso Rating'][0]  \n",
    "\n",
    "                return self._call_next(collection, score)\n",
    "\n",
    "\n",
    "class liked_cnt(BaseScorer):\n",
    "    \"\"\"Class for handling the liked count score.\n",
    "\n",
    "    Args:\n",
    "        BaseScorer (_type_): _description_\n",
    "    \"\"\"\n",
    "\n",
    "    def score(self, collection, score=0):\n",
    "        for category in dfs_para.keys():\n",
    "            n = (np.where(~np.isnan(dfs_para[str(category)]['Score Like'])))\n",
    "            n = n[0].tolist()            \n",
    "            if (category =='Bags') & (collection.main_category in (['Bags', 'Jewelry & Watches', 'Fashion Accessories'])):\n",
    "                for i in n:\n",
    "                    if i is not n[-1]:\n",
    "                        if (collection.liked_cnt >= dfs_para[str(category)]['Valor Like'][i]) & (collection.liked_cnt < dfs_para[str(category)]['Valor Like'][i+1]):\n",
    "                            score = score + dfs_para[str(category)]['Score Like'][i]*dfs_para[str(category)]['Peso Like'][0]\n",
    "\n",
    "                    elif (collection.liked_cnt >= dfs_para[str(category)]['Valor Like'][i]):\n",
    "                            score = score + dfs_para[str(category)]['Score Like'][i]*dfs_para[str(category)]['Peso Like'][0] \n",
    "\n",
    "                return self._call_next(collection, score)\n",
    "\n",
    "            if (category =='Clothes') & (collection.main_category in (['Women Clothes', 'Men Clothes'])) & (collection.sub_category not in (['Underwear & Sleepwear', 'Socks'])):\n",
    "                for i in n:\n",
    "                    if i is not n[-1]:\n",
    "                        if (collection.liked_cnt >= dfs_para[str(category)]['Valor Like'][i]) & (collection.liked_cnt < dfs_para[str(category)]['Valor Like'][i+1]):\n",
    "                            score = score + dfs_para[str(category)]['Score Like'][i]*dfs_para[str(category)]['Peso Like'][0]\n",
    "\n",
    "                    elif (collection.liked_cnt >= dfs_para[str(category)]['Valor Like'][i]):\n",
    "                            score = score + dfs_para[str(category)]['Score Like'][i]*dfs_para[str(category)]['Peso Like'][0] \n",
    "\n",
    "                return self._call_next(collection, score)\n",
    "\n",
    "            if (category =='Underwear') & (collection.sub_category in (['Underwear & Sleepwear', 'Socks'])):\n",
    "                for i in n:\n",
    "                    if i is not n[-1]:\n",
    "                        if (collection.liked_cnt >= dfs_para[str(category)]['Valor Like'][i]) & (collection.liked_cnt < dfs_para[str(category)]['Valor Like'][i+1]):\n",
    "                            score = score + dfs_para[str(category)]['Score Like'][i]*dfs_para[str(category)]['Peso Like'][0]\n",
    "\n",
    "                    elif (collection.liked_cnt >= dfs_para[str(category)]['Valor Like'][i]):\n",
    "                            score = score + dfs_para[str(category)]['Score Like'][i]*dfs_para[str(category)]['Peso Like'][0]\n",
    "\n",
    "                return self._call_next(collection, score)\n",
    "\n",
    "            if (category =='Shoes') & (collection.main_category == 'Shoes'):\n",
    "                for i in n:\n",
    "                    if i is not n[-1]:\n",
    "                        if (collection.liked_cnt >= dfs_para[str(category)]['Valor Like'][i]) & (collection.liked_cnt < dfs_para[str(category)]['Valor Like'][i+1]):\n",
    "                            score = score + dfs_para[str(category)]['Score Like'][i]*dfs_para[str(category)]['Peso Like'][0]\n",
    "\n",
    "                    elif (collection.liked_cnt >= dfs_para[str(category)]['Valor Like'][i]):\n",
    "                            score = score + dfs_para[str(category)]['Score Like'][i]*dfs_para[str(category)]['Peso Like'][0]\n",
    "\n",
    "                return self._call_next(collection, score)\n",
    "\n",
    "\n",
    "class item_stock(BaseScorer):\n",
    "    \"\"\"Class for handling the item stock score.\n",
    "\n",
    "    Args:\n",
    "        BaseScorer (_type_): _description_\n",
    "    \"\"\"\n",
    "\n",
    "    def score(self, collection, score=0):\n",
    "        for category in dfs_para.keys():\n",
    "            n = (np.where(~np.isnan(dfs_para[str(category)]['Score Estoque'])))\n",
    "            n = n[0].tolist()            \n",
    "            if (category =='Bags') & (collection.main_category in (['Bags', 'Jewelry & Watches', 'Fashion Accessories'])):\n",
    "                for i in n:\n",
    "                    if i is not n[-1]:\n",
    "                        if (collection.item_stock >= dfs_para[str(category)]['Valor Estoque'][i]) & (collection.item_stock < dfs_para[str(category)]['Valor Estoque'][i+1]):\n",
    "                            score = score + dfs_para[str(category)]['Score Estoque'][i]*dfs_para[str(category)]['Peso Estoque'][0]\n",
    "\n",
    "                    elif (collection.item_stock >= dfs_para[str(category)]['Valor Estoque'][i]):\n",
    "                            score = score + dfs_para[str(category)]['Score Estoque'][i]*dfs_para[str(category)]['Peso Estoque'][0] \n",
    "\n",
    "                return self._call_next(collection, score)\n",
    "\n",
    "            if (category =='Clothes') & (collection.main_category in (['Women Clothes', 'Men Clothes'])) & (collection.sub_category not in (['Underwear & Sleepwear', 'Socks'])):\n",
    "                for i in n:\n",
    "                    if i is not n[-1]:\n",
    "                        if (collection.item_stock >= dfs_para[str(category)]['Valor Estoque'][i]) & (collection.item_stock < dfs_para[str(category)]['Valor Estoque'][i+1]):\n",
    "                            score = score + dfs_para[str(category)]['Score Estoque'][i]*dfs_para[str(category)]['Peso Estoque'][0]\n",
    "\n",
    "                    elif (collection.item_stock >= dfs_para[str(category)]['Valor Estoque'][i]):\n",
    "                            score = score + dfs_para[str(category)]['Score Estoque'][i]*dfs_para[str(category)]['Peso Estoque'][0] \n",
    "\n",
    "                return self._call_next(collection, score)\n",
    "\n",
    "            if (category =='Underwear') & (collection.sub_category in (['Underwear & Sleepwear', 'Socks'])):\n",
    "                for i in n:\n",
    "                    if i is not n[-1]:\n",
    "                        if (collection.item_stock >= dfs_para[str(category)]['Valor Estoque'][i]) & (collection.item_stock < dfs_para[str(category)]['Valor Estoque'][i+1]):\n",
    "                            score = score + dfs_para[str(category)]['Score Estoque'][i]*dfs_para[str(category)]['Peso Estoque'][0]\n",
    "\n",
    "                    elif (collection.item_stock >= dfs_para[str(category)]['Valor Estoque'][i]):\n",
    "                            score = score + dfs_para[str(category)]['Score Estoque'][i]*dfs_para[str(category)]['Peso Estoque'][0] \n",
    "\n",
    "                return self._call_next(collection, score)\n",
    "\n",
    "            if (category =='Shoes') & (collection.main_category == 'Shoes'):\n",
    "                for i in n:\n",
    "                    if i is not n[-1]:\n",
    "                        if (collection.item_stock >= dfs_para[str(category)]['Valor Estoque'][i]) & (collection.item_stock < dfs_para[str(category)]['Valor Estoque'][i+1]):\n",
    "                            score = score + dfs_para[str(category)]['Score Estoque'][i]*dfs_para[str(category)]['Peso Estoque'][0]\n",
    "\n",
    "                    elif (collection.item_stock >= dfs_para[str(category)]['Valor Estoque'][i]):\n",
    "                            score = score + dfs_para[str(category)]['Score Estoque'][i]*dfs_para[str(category)]['Peso Estoque'][0] \n",
    "\n",
    "                return self._call_next(collection, score)\n",
    "\n",
    "\n",
    "class promo_price(BaseScorer):\n",
    "    \"\"\"Class for handling the promo price score.\n",
    "\n",
    "    Args:\n",
    "        BaseScorer (_type_): _description_\n",
    "    \"\"\"\n",
    "\n",
    "    def score(self, collection, score=0):\n",
    "        for category in dfs_para.keys():\n",
    "            n = (np.where(~np.isnan(dfs_para[str(category)]['Score Faixa de Preço'])))\n",
    "            n = n[0].tolist()\n",
    "            if (category =='Bags') & (collection.main_category in (['Bags', 'Jewelry & Watches', 'Fashion Accessories'])):\n",
    "                for i in n:\n",
    "                    if i is n[0]:\n",
    "                        if (collection.promo_price >= dfs_para[str(category)]['Valor Faixa de Preço'][i]):\n",
    "                            score = score + 10\n",
    "\n",
    "                    if i is n[-1]:\n",
    "                        if (collection.promo_price <= dfs_para[str(category)]['Valor Faixa de Preço'][i]):\n",
    "                            score = score + dfs_para[str(category)]['Score Faixa de Preço'][i]*dfs_para[str(category)]['Peso Faixa'][0]\n",
    "\n",
    "                    if i is not (n[0] or n[-1]):\n",
    "                        if (collection.promo_price <= dfs_para[str(category)]['Valor Faixa de Preço'][i]) & (collection.promo_price > dfs_para[str(category)]['Valor Faixa de Preço'][i+1]):\n",
    "                            score = score + dfs_para[str(category)]['Score Faixa de Preço'][i]*dfs_para[str(category)]['Peso Faixa'][0] \n",
    "\n",
    "                return self._call_next(collection, score)\n",
    "\n",
    "            if (category =='Clothes') & (collection.main_category in (['Women Clothes', 'Men Clothes'])) & (collection.sub_category not in (['Underwear & Sleepwear', 'Socks'])):\n",
    "                for i in n:\n",
    "                    if i is n[0]:\n",
    "                        if (collection.promo_price >= dfs_para[str(category)]['Valor Faixa de Preço'][i]):\n",
    "                            score = score + dfs_para[str(category)]['Score Faixa de Preço'][i]*dfs_para[str(category)]['Peso Faixa'][0]\n",
    "\n",
    "                    if i is n[-1]:\n",
    "                        if (collection.promo_price <= dfs_para[str(category)]['Valor Faixa de Preço'][i]):\n",
    "                            score = score + dfs_para[str(category)]['Score Faixa de Preço'][i]*dfs_para[str(category)]['Peso Faixa'][0]\n",
    "\n",
    "                    if i is not (n[0] or n[-1]):\n",
    "                        if (collection.promo_price <= dfs_para[str(category)]['Valor Faixa de Preço'][i]) & (collection.promo_price > dfs_para[str(category)]['Valor Faixa de Preço'][i+1]):\n",
    "                            score = score + dfs_para[str(category)]['Score Faixa de Preço'][i]*dfs_para[str(category)]['Peso Faixa'][0] \n",
    "\n",
    "\n",
    "                return self._call_next(collection, score)\n",
    "\n",
    "            if (category =='Underwear') & (collection.sub_category in (['Underwear & Sleepwear', 'Socks'])):\n",
    "                for i in n:\n",
    "                    if i is n[0]:\n",
    "                        if (collection.promo_price >= dfs_para[str(category)]['Valor Faixa de Preço'][i]):\n",
    "                            score = score + dfs_para[str(category)]['Score Faixa de Preço'][i]*dfs_para[str(category)]['Peso Faixa'][0]\n",
    "\n",
    "                    if i is n[-1]:\n",
    "                        if (collection.promo_price <= dfs_para[str(category)]['Valor Faixa de Preço'][i]):\n",
    "                            score = score + dfs_para[str(category)]['Score Faixa de Preço'][i]*dfs_para[str(category)]['Peso Faixa'][0]\n",
    "\n",
    "                    if i is not( n[0] or n[-1]):\n",
    "                        if (collection.promo_price <= dfs_para[str(category)]['Valor Faixa de Preço'][i]) & (collection.promo_price > dfs_para[str(category)]['Valor Faixa de Preço'][i+1]):\n",
    "                            score = score + dfs_para[str(category)]['Score Faixa de Preço'][i]*dfs_para[str(category)]['Peso Faixa'][0] \n",
    "\n",
    "                return self._call_next(collection, score)\n",
    "\n",
    "            if (category =='Shoes') & (collection.main_category == 'Shoes'):\n",
    "                for i in n:\n",
    "                    if i is n[0]:\n",
    "                        if (collection.promo_price >= dfs_para[str(category)]['Valor Faixa de Preço'][i]):\n",
    "                            score = score + dfs_para[str(category)]['Score Faixa de Preço'][i]*dfs_para[str(category)]['Peso Faixa'][0]\n",
    "\n",
    "                    if i is n[-1]:\n",
    "                        if (collection.promo_price <= dfs_para[str(category)]['Valor Faixa de Preço'][i]):\n",
    "                            score = score + dfs_para[str(category)]['Score Faixa de Preço'][i]*dfs_para[str(category)]['Peso Faixa'][0]\n",
    "\n",
    "                    if i is not (n[0] or n[-1]):\n",
    "                        if (collection.promo_price <= dfs_para[str(category)]['Valor Faixa de Preço'][i]) & (collection.promo_price > dfs_para[str(category)]['Valor Faixa de Preço'][i+1]):\n",
    "                            score = score + dfs_para[str(category)]['Score Faixa de Preço'][i]*dfs_para[str(category)]['Peso Faixa'][0] \n",
    "                return self._call_next(collection, score)\n",
    "\n",
    "\n",
    "class brl_gmv(BaseScorer):\n",
    "    \"\"\"Class for handling the GMV score.\n",
    "\n",
    "    Args:\n",
    "        BaseScorer (_type_): _description_\n",
    "    \"\"\"\n",
    "    def score(self, collection, score=0):\n",
    "        for category in dfs_para.keys():\n",
    "            n = (np.where(~np.isnan(dfs_para[str(category)]['Score GMV'])))\n",
    "            n = n[0].tolist()            \n",
    "            if (category =='Bags') & (collection.main_category in (['Bags', 'Jewelry & Watches', 'Fashion Accessories'])):\n",
    "                for i in n:\n",
    "                    if i is not n[-1]:\n",
    "                        if (collection.brl_gmv >= dfs_para[str(category)]['Valor GMV'][i]) & (collection.brl_gmv < dfs_para[str(category)]['Valor GMV'][i+1]):\n",
    "                            score = score + dfs_para[str(category)]['Score GMV'][i]*dfs_para[str(category)]['Peso GMV'][0]\n",
    "\n",
    "                    elif (collection.brl_gmv >= dfs_para[str(category)]['Valor GMV'][i]):\n",
    "                            score = score + dfs_para[str(category)]['Score GMV'][i]*dfs_para[str(category)]['Peso GMV'][0] \n",
    "\n",
    "                return self._call_next(collection, score)\n",
    "\n",
    "            if (category =='Clothes') & (collection.main_category in (['Women Clothes', 'Men Clothes'])) & (collection.sub_category not in (['Underwear & Sleepwear', 'Socks'])):\n",
    "                for i in n:\n",
    "                    if i is not n[-1]:\n",
    "                        if (collection.brl_gmv >= dfs_para[str(category)]['Valor GMV'][i]) & (collection.brl_gmv < dfs_para[str(category)]['Valor GMV'][i+1]):\n",
    "                            score = score + dfs_para[str(category)]['Score GMV'][i]*dfs_para[str(category)]['Peso GMV'][0]\n",
    "\n",
    "                    elif (collection.brl_gmv >= dfs_para[str(category)]['Valor GMV'][i]):\n",
    "                            score = score + dfs_para[str(category)]['Score GMV'][i]*dfs_para[str(category)]['Peso GMV'][0]\n",
    "\n",
    "                return self._call_next(collection, score)\n",
    "\n",
    "            if (category =='Underwear') & (collection.sub_category in (['Underwear & Sleepwear', 'Socks'])):\n",
    "                for i in n:\n",
    "                    if i is not n[-1]:\n",
    "                        if (collection.brl_gmv >= dfs_para[str(category)]['Valor GMV'][i]) & (collection.brl_gmv < dfs_para[str(category)]['Valor GMV'][i+1]):\n",
    "                            score = score + dfs_para[str(category)]['Score GMV'][i]*dfs_para[str(category)]['Peso GMV'][0]\n",
    "\n",
    "                    elif (collection.brl_gmv >= dfs_para[str(category)]['Valor GMV'][i]):\n",
    "                            score = score + dfs_para[str(category)]['Score GMV'][i]*dfs_para[str(category)]['Peso GMV'][0]\n",
    "\n",
    "                return self._call_next(collection, score)\n",
    "\n",
    "            if (category =='Shoes') & (collection.main_category == 'Shoes'):\n",
    "                for i in n:\n",
    "                    if i is not n[-1]:\n",
    "                        if (collection.brl_gmv >= dfs_para[str(category)]['Valor GMV'][i]) & (collection.brl_gmv < dfs_para[str(category)]['Valor GMV'][i+1]):\n",
    "                            score = score + dfs_para[str(category)]['Score GMV'][i]*dfs_para[str(category)]['Peso GMV'][0]\n",
    "\n",
    "                    elif (collection.brl_gmv >= dfs_para[str(category)]['Valor GMV'][i]):\n",
    "                            score = score + dfs_para[str(category)]['Score GMV'][i]*dfs_para[str(category)]['Peso GMV'][0]\n",
    "\n",
    "                return self._call_next(collection, score)\n",
    "\n",
    "\n",
    "class base(BaseScorer):\n",
    "    \n",
    "    \"\"\"Class for handling the type of the deal score.\n",
    "\n",
    "    Args:\n",
    "        BaseScorer (_type_): _description_\n",
    "    \"\"\"\n",
    "\n",
    "    def score(self, collection, score=0):\n",
    "        for category in dfs_para.keys():\n",
    "            n = (np.where(~np.isnan(dfs_para[str(category)]['Score Base'])))\n",
    "            n = n[0].tolist()            \n",
    "            if (category =='Bags') & (collection.main_category in (['Bags', 'Jewelry & Watches', 'Fashion Accessories'])):\n",
    "                for i in n:\n",
    "                    if (collection.base == dfs_para[str(category)]['Valor Base'][i]):\n",
    "                        score = score + dfs_para[str(category)]['Score Base'][i]*dfs_para[str(category)]['Peso Base'][0] \n",
    "\n",
    "                return self._call_next(collection, score)\n",
    "\n",
    "            if (category =='Clothes') & (collection.main_category in (['Women Clothes', 'Men Clothes'])) & (collection.sub_category not in (['Underwear & Sleepwear', 'Socks'])):\n",
    "                for i in n:\n",
    "                    if (collection.base == dfs_para[str(category)]['Valor Base'][i]):\n",
    "                        score = score + dfs_para[str(category)]['Score Base'][i]*dfs_para[str(category)]['Peso Base'][0] \n",
    "\n",
    "                return self._call_next(collection, score)\n",
    "\n",
    "            if (category =='Underwear') & (collection.sub_category in (['Underwear & Sleepwear', 'Socks'])):\n",
    "                for i in n:\n",
    "                    if (collection.base == dfs_para[str(category)]['Valor Base'][i]):\n",
    "                        score = score + dfs_para[str(category)]['Score Base'][i]*dfs_para[str(category)]['Peso Base'][0] \n",
    "\n",
    "                return self._call_next(collection, score)\n",
    "\n",
    "            if (category =='Shoes') & (collection.main_category == 'Shoes'):\n",
    "                for i in n:\n",
    "                    if (collection.base == dfs_para[str(category)]['Valor Base'][i]):\n",
    "                        score = score + dfs_para[str(category)]['Score Base'][i]*dfs_para[str(category)]['Peso Base'][0] \n",
    "\n",
    "                return self._call_next(collection, score)\n",
    "\n",
    "scorer = BaseScorer.chain([\n",
    "    sales(),\n",
    "    rating(),\n",
    "    liked_cnt(),\n",
    "    item_stock(),\n",
    "    promo_price(),\n",
    "    brl_gmv(),\n",
    "    base()\n",
    "])\n",
    "\n",
    "# score file\n",
    "dfs_para = pd.read_excel('../data/score_collections.xlsx', sheet_name=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Parameters file: loading and treating**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading parameters file\n",
    "df_para = pd.read_excel('../campaigns/'+YEAR+'/'+MONTH+'/'+CAMPAIGN+'/parameters-'+CAMPAIGN+'.xlsx')\n",
    "df_para.set_index(['collection'], inplace=True)\n",
    "\n",
    "\n",
    "# treating int columns\n",
    "int_col = ['min_stock', 'max_items']\n",
    "df_para[int_col] = df_para[int_col].apply(lambda x: x.astype('int64'))\n",
    "\n",
    "# treating float columns\n",
    "float_col = ['min_discount', 'max_discount', 'min_price', 'max_price']\n",
    "df_para[float_col] = df_para[float_col].apply(lambda x: x.astype('float'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Stock file: loading and treating**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading stock\n",
    "estoque_or = pd.read_csv('../campaigns/'+YEAR+'/'+MONTH+'/'+CAMPAIGN+'/stock-'+CAMPAIGN+'.csv')\n",
    "\n",
    "# TODO: change cluster category\n",
    "estoque_or = estoque_or[estoque_or[\"cluster_category\"] == \"Fashion\"]\n",
    "\n",
    "# rename new category tree to use the old ones in order to have consistent items\n",
    "estoque_or.rename(columns={'main_category': 'new_main_category',\n",
    "                           'sub_category': 'new_sub_category',\n",
    "                           'level3_category': 'new_level3_category',\n",
    "                           'old_category': 'main_category',\n",
    "                           'old_sub_category': 'sub_category',\n",
    "                           'level3_old_category':'level3_category',\n",
    "                           'item_id': 'itemid_e',\n",
    "                           'price': 'original_price',\n",
    "                           'stock': 'item_stock'},\n",
    "                  inplace=True)\n",
    "\n",
    "estoque_or = estoque_or[['itemid_e', 'main_category', 'sub_category', 'level3_category', 'original_price', 'item_stock',\n",
    "                         'rating_total_cnt', 'liked_cnt', 'rating_score', 'item_name', 'shop_id']]\n",
    "\n",
    "estoque_or['rating_score'] = estoque_or['rating_score'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Sales file: loading and treating**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading\n",
    "venda_or = pd.read_csv('../campaigns/'+YEAR+'/'+MONTH+'/'+CAMPAIGN+'/sales-'+CAMPAIGN+'.csv')\n",
    "\n",
    "# treating\n",
    "venda_or.rename(columns={'item_id': 'itemid_v'}, inplace=True)\n",
    "venda_or = venda_or[['itemid_v', 'units_sold', 'brl_gmv', 'gross_orders']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Deal pool: loading and treating**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total deals in deal pool: 208015\n",
      "Total deals within campaign dates: 27901\n",
      "Total deals after treating: 26800\n"
     ]
    }
   ],
   "source": [
    "# Loading deal pool\n",
    "# TODO: change spreadsheet_key and worksheet according to your deal pool\n",
    "\n",
    "sku_negociados_original = get_spreadsheet_dataframe(\n",
    "    '1mASRUOvyjJ0dtU43xhnKj4iEN02uWypxIQsXWAHSXRA',\n",
    "    'Deal Pool')\n",
    "\n",
    "# Treating deal pool\n",
    "sku_negociados_or = sku_negociados_original.copy(deep=False)\n",
    "print('Total deals in deal pool:', sku_negociados_or.shape[0])\n",
    "\n",
    "# Treating is_collection and campaign dates\n",
    "CAMPAIGN_START_DATE_CONDITION = sku_negociados_or['start_date'] == CAMPAIGN_ENTRY_DATE\n",
    "CAMPAIGN_END_DATE_CONDITION = sku_negociados_or['end_date'] == CAMPAIGN_EXIT_DATE\n",
    "IS_COLLECTION_CONDITION = sku_negociados_or['collections'] == 'Sim'\n",
    "sku_negociados_or = sku_negociados_or[CAMPAIGN_START_DATE_CONDITION & CAMPAIGN_END_DATE_CONDITION & IS_COLLECTION_CONDITION]\n",
    "sku_negociados_or.drop_duplicates('item_id', inplace=True)\n",
    "print('Total deals within campaign dates:', sku_negociados_or.shape[0])\n",
    "\n",
    "# Treating blank RM and prices\n",
    "RM_IS_BLANK = sku_negociados_or['rm_name'] == ''\n",
    "PRICE_IS_BLANK = sku_negociados_or['deal_price_after_rebate'] == {'', '.'}\n",
    "sku_negociados_or.drop(sku_negociados_or.loc[RM_IS_BLANK].index, inplace=True)\n",
    "sku_negociados_or.drop(sku_negociados_or.loc[PRICE_IS_BLANK].index, inplace=True)\n",
    "sku_negociados_or['deal_price_after_rebate'] = pd.to_numeric(sku_negociados_or['deal_price_after_rebate'],\n",
    "                                                             errors='coerce',\n",
    "                                                             downcast='float')\n",
    "sku_negociados_or.dropna(subset=['deal_price_after_rebate'], inplace=True)\n",
    "\n",
    "# Treating price formatting\n",
    "deal_price_list = sku_negociados_or['deal_price_after_rebate'].tolist()\n",
    "deal_price_list = [str(i) for i in deal_price_list]\n",
    "deal_price_list = [i.replace('R$', '').replace(',', '.').strip() for i in deal_price_list]\n",
    "deal_price_list = [float(i) for i in deal_price_list]\n",
    "sku_negociados_or['deal_price_after_rebate'] = deal_price_list\n",
    "\n",
    "# Treating item_id\n",
    "sku_negociados_or['item_id'] = pd.to_numeric(sku_negociados_or['item_id'], errors='coerce')\n",
    "sku_negociados_or.dropna(subset=['item_id'], inplace=True)\n",
    "sku_negociados_or['item_id'] = sku_negociados_or['item_id'].astype('float').astype('int64')\n",
    "\n",
    "# Treating blank stock values\n",
    "df_item_id_promo_stock = sku_negociados_or[['item_id', 'promo_stock']]\n",
    "lista = ['']\n",
    "lista = df_item_id_promo_stock.loc[df_item_id_promo_stock['promo_stock'].isin(lista)]['item_id'].tolist()\n",
    "BLANK_STOCK = estoque_or['itemid_e'].isin(lista)\n",
    "estoque_null = estoque_or[BLANK_STOCK]\n",
    "estoque_null = estoque_null[['itemid_e', 'item_stock']]\n",
    "estoque_null.rename(columns={'itemid_e': 'itemid_n', 'item_stock': 'item_stock_n'}, inplace=True)\n",
    "sku_negociados_or = pd.merge(sku_negociados_or, estoque_null, how='left', left_on='item_id', right_on='itemid_n')\n",
    "sku_negociados_or.loc[sku_negociados_or['promo_stock'] == '', 'promo_stock'] = sku_negociados_or['item_stock_n']\n",
    "sku_negociados_or = pd.merge(sku_negociados_or, estoque_or, left_on='item_id', right_on='itemid_e', how='left')\n",
    "\n",
    "# treating missing price values\n",
    "lista = sku_negociados_or['original_price'].tolist()\n",
    "lista = [str(i) for i in lista]\n",
    "sku_negociados_or['original_price'] = lista\n",
    "sku_negociados_or.drop(sku_negociados_or.loc[sku_negociados_or['original_price'] == 'nan'].index, inplace=True)\n",
    "\n",
    "# creating discount column\n",
    "lista = sku_negociados_or['original_price'].tolist()\n",
    "lista = [float(i) for i in lista]\n",
    "sku_negociados_or['original_price'] = lista\n",
    "sku_negociados_or['discount'] = (1 - (sku_negociados_or['deal_price_after_rebate'] / sku_negociados_or['original_price']))\n",
    "\n",
    "# Merging deal pool with sales df\n",
    "sku_negociados_or.sort_values('item_id', inplace=True, ignore_index=True)\n",
    "venda_or.sort_values('itemid_v', inplace=True, ignore_index=True)\n",
    "sku_negociados_or = pd.merge(sku_negociados_or, venda_or, left_on='item_id', right_on='itemid_v', how='left')\n",
    "sku_negociados_or['units_sold'] = sku_negociados_or['units_sold'].fillna(0)\n",
    "sku_negociados_or['gross_orders'] = sku_negociados_or['gross_orders'].fillna(0)\n",
    "\n",
    "# Renaming columns\n",
    "columns_names_sku = {\n",
    "    'start_date':'entry_day',\n",
    "    'end_date':'exit_day',\n",
    "    'shop_id':'shopid',\n",
    "    'item_id':'itemid',\n",
    "    'deal_price_after_rebate':'promo_price',\n",
    "    'promo_stock':'campaign_stock',\n",
    "    'collections':'is_collection',\n",
    "    'rm_name':'RM'\n",
    "    }\n",
    "\n",
    "sku_negociados_or.rename(columns=columns_names_sku, inplace=True)\n",
    "\n",
    "# Selecting columns\n",
    "sku_negociados_or = sku_negociados_or[\n",
    "        ['exit_day', 'entry_day', 'shopid',\n",
    "         'itemid', 'main_category', 'sub_category',\n",
    "         'level3_category', 'original_price','promo_price',\n",
    "         'discount', 'campaign_stock', 'item_stock',\n",
    "         'is_collection', 'item_name','units_sold',\n",
    "         'rating_total_cnt', 'liked_cnt', 'brl_gmv',\n",
    "         'gross_orders', 'rating_score', 'RM', 'collection_fs']]\n",
    "\n",
    "# Treating stock values\n",
    "sku_negociados_or['new_estoque'] = sku_negociados_or['campaign_stock'].str.extract('(\\d+)')\n",
    "sku_negociados_or.loc[sku_negociados_or['new_estoque'].isnull(), 'new_estoque'] = sku_negociados_or['campaign_stock']\n",
    "sku_negociados_or['new_estoque'] = pd.to_numeric(sku_negociados_or['new_estoque'], errors='coerce')\n",
    "sku_negociados_or['campaign_stock'] = sku_negociados_or['new_estoque']\n",
    "sku_negociados_or.drop(columns='new_estoque', inplace=True)\n",
    "lista = sku_negociados_or['campaign_stock'].tolist()\n",
    "lista = [str(i) for i in lista]\n",
    "sku_negociados_or['campaign_stock'] = lista\n",
    "sku_negociados_or.drop(sku_negociados_or.loc[sku_negociados_or['campaign_stock'] == 'nan'].index, inplace=True)\n",
    "sku_negociados_or['campaign_stock'] = sku_negociados_or['campaign_stock'].astype('float').astype('int64')\n",
    "\n",
    "# Treating dates\n",
    "sku_negociados_or['entry_day'] = sku_negociados_or['entry_day'].apply(pd.to_datetime, errors='coerce')\n",
    "sku_negociados_or['exit_day'] = sku_negociados_or['exit_day'].apply(pd.to_datetime, errors='coerce')\n",
    "\n",
    "\n",
    "# Adding rating column\n",
    "sku_negociados_or['Rxq'] = sku_negociados_or['rating_total_cnt'] * sku_negociados_or['rating_score']\n",
    "\n",
    "# Treating shopid\n",
    "sku_negociados_or['shopid'] = sku_negociados_or['shopid'].astype(np.int64)\n",
    "\n",
    "\n",
    "print('Total deals after treating:', sku_negociados_or.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Self nominated deals: loading and treating**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading self nominated deals\n",
    "try:\n",
    "    self_nominated_original = pd.read_csv('../campaigns/'+YEAR+'/'+MONTH+'/'+CAMPAIGN+'/self-'+CAMPAIGN+'.csv')\n",
    "except FileNotFoundError:\n",
    "    self_nominated_original = pd.read_excel('../campaigns/'+YEAR+'/'+MONTH+'/'+CAMPAIGN+'/self-'+CAMPAIGN+'.xlsx')\n",
    "\n",
    "# TODO: change L1 categories\n",
    "l1_categories = [\n",
    "    'Baby & Kids Fashion', 'Bags', 'Fashion Accessories',\n",
    "    'Men Clothes', 'Shoes', 'Underwear & Sleepwear',\n",
    "    'Women Clothes'\n",
    "    ]\n",
    "\n",
    "self_nominated_or = self_nominated_original.copy(deep=True)\n",
    "IS_CLUSTER_CATEGORIES = self_nominated_or['main_category_id'].isin(l1_categories)\n",
    "self_nominated_or = self_nominated_or[IS_CLUSTER_CATEGORIES]\n",
    "\n",
    "self_nominated_or = self_nominated_or[['shop_id', 'item_id', 'review_status', 'promotion_price']]\n",
    "self_nominated_or.rename(columns={'item_id': 'itemid', 'shop_id': 'shopid', 'promotion_price': 'promo_price'}, inplace=True)\n",
    "\n",
    "# Cross with stock and sales base in order to get categories and other useful info\n",
    "self_nominated_or = pd.merge(self_nominated_or, estoque_or, left_on='itemid', right_on='itemid_e', how='inner')\n",
    "self_nominated_or = pd.merge(self_nominated_or, venda_or, left_on='itemid', right_on='itemid_v', how='left')\n",
    "\n",
    "# Dropping columns\n",
    "self_nominated_or.drop(['itemid_e', 'itemid_v'], axis=1, inplace=True)\n",
    "\n",
    "# Promo_price treating\n",
    "promo_price_list = self_nominated_or['promo_price'].tolist()\n",
    "promo_price_list = [str(i) for i in promo_price_list]\n",
    "promo_price_list = [i.replace(',', '.') for i in promo_price_list]\n",
    "promo_price_list = [float(i) for i in promo_price_list]\n",
    "self_nominated_or['promo_price'] = promo_price_list\n",
    "\n",
    "# Discount column\n",
    "self_nominated_or['discount'] = 1 - (self_nominated_or['promo_price'] / self_nominated_or['original_price'])\n",
    "\n",
    "# Adding Rxq column\n",
    "self_nominated_or['Rxq'] = self_nominated_or['rating_total_cnt'] * self_nominated_or['rating_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **BI: loading and treating**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading BI\n",
    "bi_original = pd.read_csv('../campaigns/'+YEAR+'/'+MONTH+'/'+CAMPAIGN+'/bi-'+CAMPAIGN+'.csv')\n",
    "\n",
    "bi_or = bi_original.copy(deep=False)\n",
    "bi_or.rename(columns={\n",
    "    'item_price_before_discount': 'original_price',\n",
    "    'item_price': 'promo_price',\n",
    "    'shop_id': 'shopid',\n",
    "    'item_id': 'itemid',\n",
    "    'liked_count': 'liked_cnt'\n",
    "    },\n",
    "    inplace=True)\n",
    "\n",
    "# Treating columns type\n",
    "bi_or['promo_price'] = bi_or['promo_price'].astype('float')\n",
    "bi_or['rating_score'] = bi_or['rating_score'].astype('float')\n",
    "bi_or['original_price'] = bi_or['original_price'].astype('float')\n",
    "bi_or['item_stock'] = bi_or['item_stock'].astype('int64')\n",
    "bi_or['liked_cnt'] = bi_or['liked_cnt'].astype('int64')\n",
    "bi_or[\"rating_count\"] = bi_or[\"rating_count\"].astype('int64')\n",
    "bi_or['Rxq'] = bi_or['rating_count'] * bi_or['rating_score']\n",
    "\n",
    "# Creating discount column\n",
    "bi_or['discount'] = 1 - (bi_or['promo_price'] / bi_or['original_price'])\n",
    "\n",
    "# Getting sales info\n",
    "bi_or = pd.merge(bi_or, venda_or, left_on='itemid', right_on='itemid_v', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Blacklists: loading and treating**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unidecode_lower_list(list_to_unidecode):\n",
    "    list_to_unidecode = [x.lower() for x in list_to_unidecode]\n",
    "    list_to_unidecode = [unidecode(x) for x in list_to_unidecode]\n",
    "    unidecoded_list = list(set(list_to_unidecode))\n",
    "    return unidecoded_list\n",
    "\n",
    "blacklist_spreadsheet_key = '1pwe-z4SVuiV-nlSLi0rj3Pe8i1BS9v3ReEU33OazizI'\n",
    "\n",
    "# blackword\n",
    "blackword = unidecode_lower_list(get_spreadsheet_dataframe(blacklist_spreadsheet_key, 'blackword').word.values.tolist())\n",
    "\n",
    "# new users\n",
    "new_users_item_list = get_spreadsheet_dataframe(blacklist_spreadsheet_key, 'new_users').item_id.values.tolist()\n",
    "\n",
    "# penalty sellers\n",
    "penalty_sellers_shop_list = get_spreadsheet_dataframe(blacklist_spreadsheet_key, 'penalty_sellers').shop_id.values.tolist()\n",
    "\n",
    "# transportadoras\n",
    "shop_list_3pl = get_spreadsheet_dataframe(blacklist_spreadsheet_key, '3pl').shop_id.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Main looping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def engine_collections():\n",
    "    \n",
    "    microsite_id_list = []\n",
    "    repeated_item_ban_list = []\n",
    "    \n",
    "    sku_negociados = sku_negociados_or.copy()\n",
    "    self_nominated = self_nominated_or.copy()\n",
    "    bi = bi_or.copy()\n",
    "    sku_negociados['base'] = 'SKU'\n",
    "    self_nominated['base'] = 'SELF'\n",
    "    bi['base'] = 'BI'\n",
    "    df_blank_collections = pd.DataFrame()\n",
    "    df_original = pd.DataFrame()\n",
    "    \n",
    "    print('Starting...')\n",
    "    \n",
    "    df_original = pd.concat([sku_negociados, self_nominated, bi], ignore_index=True)\n",
    "    print('Total deals (SKU, self and BI):', df_original.shape[0])\n",
    "    \n",
    "    df_original['item_name_unidecode'] = df_original['item_name'].apply(lambda x: unidecode(x))\n",
    "    df_original = df_original[~df_original.item_name_unidecode.str.contains('|'.join(blackword), case=False, flags=re.IGNORECASE, na=False, regex=True)]    \n",
    "    df_original.sort_values('base', ascending=False, inplace=True)\n",
    "    df_original.drop_duplicates(subset=[\"shopid\", \"itemid\"], keep='first', inplace=True)\n",
    "    print('Blackword filter:', df_original.shape[0])\n",
    "    \n",
    "    # TODO: change L1 categories\n",
    "    l1 = [\n",
    "            'Baby & Kids Fashion', 'Bags', 'Fashion Accessories',\n",
    "            'Men Clothes', 'Shoes', 'Underwear & Sleepwear',\n",
    "            'Women Clothes', 'Jewelry and Watches', 'Jewelry & Watches'\n",
    "            ]\n",
    "    \n",
    "    df_original = df_original[df_original['main_category'].isin(l1_categories)]\n",
    "    print('Only cluster category filter:', df_original.shape[0])\n",
    "    \n",
    "    df_original = df_original[~df_original.itemid.isin(new_users_item_list)]\n",
    "    print('New users filter:', df_original.shape[0])\n",
    "    \n",
    "    df_original = df_original[~df_original.shopid.isin(penalty_sellers_shop_list)]\n",
    "    print('Penalty sellers filter', df_original.shape[0])\n",
    "    \n",
    "    for index, df_parameters in df_para.iterrows():\n",
    "        # Code that avoid repeated items across the same microsite\n",
    "        if df_parameters['microsite_id'] in microsite_id_list:\n",
    "            pass\n",
    "        else:\n",
    "            microsite_id_list.clear()\n",
    "            repeated_item_ban_list.clear()\n",
    "            microsite_id_list.append(df_parameters['microsite_id'])\n",
    "        \n",
    "        collection_name = str(df_parameters.microsite_name) +' - '+ str(df_parameters.name)\n",
    "        print('\\n######### Generating', collection_name, '#########')\n",
    "        \n",
    "        df = df_original.copy()\n",
    "                \n",
    "        try:\n",
    "            \n",
    "            #########################\n",
    "            #### repeated_items #####\n",
    "            #########################\n",
    "            \n",
    "            df = df[~df.itemid.isin(repeated_item_ban_list)]\n",
    "            print('Repeated items across microsite drop:', df.shape[0])\n",
    "\n",
    "            #########################\n",
    "            ####### insert_bi #######\n",
    "            #########################\n",
    "                        \n",
    "            if df_parameters['insert_bi'] == True:\n",
    "                print('Collection with BI:', df.shape[0])\n",
    "            else:\n",
    "                df = df[~(df['base'] == 'BI')]\n",
    "                print('Collection without BI:', df.shape[0])\n",
    "            \n",
    "            #########################\n",
    "            ######### price #########\n",
    "            #########################\n",
    "            \n",
    "            if pd.notna(df_parameters['min_price']):\n",
    "                DF_ABOVE_MIN_PRICE = df['promo_price'] >= df_parameters['min_price']\n",
    "                DF_BELOW_MAX_PRICE = df['promo_price'] <= df_parameters['max_price']\n",
    "                DF_BETWEEN_MIN_AND_MAX_PRICE = (DF_ABOVE_MIN_PRICE & DF_BELOW_MAX_PRICE)\n",
    "                df = df[DF_BETWEEN_MIN_AND_MAX_PRICE]\n",
    "                print('Price filter:', df.shape[0])\n",
    "                            \n",
    "            #########################\n",
    "            ####### discount ########\n",
    "            #########################       \n",
    "\n",
    "            if pd.notna(df_parameters['min_discount']):\n",
    "                DF_ABOVE_MIN_DISCOUNT = df['discount'] >= df_parameters['min_discount']\n",
    "                DF_BELOW_MAX_DISCOUNT = df['discount'] <= df_parameters['max_discount']\n",
    "                DF_BETWEEN_MIN_AND_MAX_DISCOUNT = (DF_ABOVE_MIN_DISCOUNT & DF_BELOW_MAX_DISCOUNT)\n",
    "                df = df[DF_BETWEEN_MIN_AND_MAX_DISCOUNT]\n",
    "                print('Discount filter:', df.shape[0])\n",
    "                        \n",
    "            #########################\n",
    "            ####### category ########\n",
    "            #########################  \n",
    "            \n",
    "            if pd.notna(df_parameters['main_category']):\n",
    "                category_list = ConvertList(df_parameters['main_category'])\n",
    "                DF_ISIN_MAIN_CATEGORY = df['main_category'].isin(category_list)\n",
    "                df = df[DF_ISIN_MAIN_CATEGORY]\n",
    "            \n",
    "            if pd.notna(df_parameters['sub_category']):\n",
    "                sub_category_list = ConvertList(df_parameters['sub_category'])\n",
    "                DF_ISIN_SUB_CATEGORY = df['sub_category'].isin(sub_category_list)\n",
    "                df = df[DF_ISIN_SUB_CATEGORY]\n",
    "            \n",
    "            if pd.notna(df_parameters['l3_category']):\n",
    "                l3_category_list = ConvertList(df_parameters['l3_category'])\n",
    "                DF_ISIN_L3_CATEGORY = df['level3_category'].isin(l3_category_list)\n",
    "                df = df[DF_ISIN_L3_CATEGORY]\n",
    "            \n",
    "            print('Category filter:', df.shape[0])\n",
    "            \n",
    "            #########################\n",
    "            ####### keywords ########\n",
    "            #########################\n",
    "            \n",
    "            if pd.notna(df_parameters['keywords']):\n",
    "                keywords_list = ConvertList(df_parameters['keywords'])\n",
    "                keywords_list = [unidecode(x) for x in keywords_list]\n",
    "                df = df[df.item_name_unidecode.str.contains('|'.join(keywords_list), case=False, flags=re.IGNORECASE, na=False, regex=True)]\n",
    "                print('Keywords filter:', df.shape[0])\n",
    "                        \n",
    "            #########################\n",
    "            ########## 3pl ##########\n",
    "            #########################\n",
    "            \n",
    "            if df_parameters['3pl'] == True:\n",
    "                df = df[df.shopid.isin(shop_list_3pl)]\n",
    "                print('3pl filter:', df.shape[0])\n",
    "                                \n",
    "            #########################\n",
    "            ####### max_items #######\n",
    "            #########################\n",
    "            \n",
    "            if pd.notna(df_parameters['max_items']):\n",
    "                df = df.iloc[:df_parameters['max_items']]\n",
    "                print('Max items filter:', df.shape[0])\n",
    "            else:\n",
    "                df = df.iloc[:1000]\n",
    "                print('Max items filter:', df.shape[0])\n",
    "                 \n",
    "            #########################\n",
    "            ######### score #########\n",
    "            #########################       \n",
    "            \n",
    "            print('Applying score...', df.shape[0])\n",
    "            df = classifier(df)\n",
    "            \n",
    "            #########################\n",
    "            ###### sort by cat ######\n",
    "            #########################  \n",
    "            \n",
    "            print('Sorting by category...', df.shape[0])\n",
    "            # Sorting by category\n",
    "            if df.sub_category.unique().shape[0] <= 3:\n",
    "                df = sort_by_cat(df,'level3_category')\n",
    "            else:\n",
    "                df = sort_by_cat(df,'sub_category')\n",
    "                \n",
    "            #########################\n",
    "            ### best_seller_order ###\n",
    "            #########################\n",
    "            \n",
    "            if df_parameters['best_seller_order'] == True:\n",
    "                print('Sorting by gross_orders...', df.shape[0])\n",
    "                df.sort_values('gross_orders', ascending=False, inplace=True)\n",
    "            \n",
    "            #########################\n",
    "            ### rank/final columns ##\n",
    "            #########################\n",
    "                  \n",
    "            # Creating rank column\n",
    "            print('Creating rank column...', df.shape[0])\n",
    "            df.reset_index(drop = True, inplace = True)\n",
    "            df['rank'] = df.index + 1\n",
    "                    \n",
    "            # Final columns\n",
    "            df['cluster'] = df_parameters['cluster']\n",
    "            df['microsite_id'] = df_parameters['microsite_id']\n",
    "            df['collection_id'] = df_parameters['collection_id']\n",
    "            \n",
    "            print('Applying final columns...', df.shape[0])\n",
    "            final_columns = [\n",
    "                'shopid',\n",
    "                'itemid',\n",
    "                'rank',\n",
    "                'base',\n",
    "                'item_name',\n",
    "                'main_category',\n",
    "                'cluster',\n",
    "                'microsite_id',\n",
    "                'collection_id',\n",
    "                'score',\n",
    "                'promo_price',\n",
    "                'gross_orders',\n",
    "                'collection_fs',\n",
    "                'original_price',\n",
    "                'discount'\n",
    "            ]\n",
    "            \n",
    "            df = df[final_columns]\n",
    "            \n",
    "            first100items = df.head(50).itemid.values.tolist()\n",
    "            repeated_item_ban_list.extend(first100items)\n",
    "            \n",
    "        except KeyError as e:\n",
    "            print('Collection without items. Going to the next.')\n",
    "            continue\n",
    "        \n",
    "        #########################\n",
    "        ##### drive upload ######\n",
    "        #########################\n",
    "        \n",
    "        # Try to send collection to Google Drive\n",
    "        collection_already_exists = False\n",
    "        success = False\n",
    "        sleep_time = 2\n",
    "        \n",
    "        while not success:\n",
    "            try:\n",
    "                delivery_folder_file_list = drive.ListFile({'q': f\"'{CLUSTER_DELIVERY_FOLDER_ID}' in parents and trashed=false\"}).GetList()\n",
    "                success = True\n",
    "            except Exception as e:\n",
    "                print('Connection failed. Exception:', e)\n",
    "        \n",
    "        collection_already_exists = False        \n",
    "        for collection in delivery_folder_file_list:\n",
    "            sleep_time = 2\n",
    "            success = False\n",
    "            while not success:\n",
    "                try:\n",
    "                    if (str(str(df_parameters['collection_id']) + \" - \" + str(df_parameters.name)) == str(collection['title'])):\n",
    "                        collection_already_exists = True\n",
    "                        print('Collection already exists. Updating it...')\n",
    "                        spreadsheet_id = collection['id']\n",
    "                        gc = gspread_start()\n",
    "                        sh = gc.open_by_key(spreadsheet_id)\n",
    "                        worksheet_collection = sh.get_worksheet(0)\n",
    "                        worksheet_collection.clear()\n",
    "                        set_with_dataframe(worksheet_collection, df, col=1, row=1)\n",
    "                        print('Collection updated.')\n",
    "                    success = True\n",
    "                except Exception as e:\n",
    "                    print('Fail. Exception occurred. Waiting ' + str(sleep_time) + ' seconds to try again.')\n",
    "                    time.sleep(sleep_time)\n",
    "                    sleep_time *= 2\n",
    "                \n",
    "        if not collection_already_exists:\n",
    "            sleep_time = 2\n",
    "            success = False\n",
    "            while not success:\n",
    "                try:\n",
    "                    print('Creating collection file...')\n",
    "                    file = drive.CreateFile({'title': str(str(df_parameters['collection_id']) + \" - \" + str(df_parameters.name)),\n",
    "                                 'mimeType': 'application/vnd.google-apps.spreadsheet',\n",
    "                                 'parents': [{'id': CLUSTER_DELIVERY_FOLDER_ID}]})\n",
    "                    \n",
    "                    file.Upload()\n",
    "                    \n",
    "                    file.InsertPermission({\n",
    "                    'type': 'domain',\n",
    "                    'value': 'shopee.com',\n",
    "                    'role': 'writer'\n",
    "                    })\n",
    "                    \n",
    "                    file.InsertPermission({\n",
    "                    'type': 'user',\n",
    "                    'value': 'sheetsvini@sheetsvini.iam.gserviceaccount.com',\n",
    "                    'role': 'writer'\n",
    "                    })\n",
    "                    \n",
    "                    spreadsheet_id = file['id']\n",
    "                    \n",
    "                    gc = gspread_start()\n",
    "                    \n",
    "                    sh = gc.open_by_key(spreadsheet_id)\n",
    "                    \n",
    "                    worksheet_collection = sh.get_worksheet(0)\n",
    "                    \n",
    "                    set_with_dataframe(worksheet_collection, df, col=1, row=1)\n",
    "                    success = True\n",
    "                    print('Collection created.')\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print('Fail. Exception occurred. Waiting ' + str(sleep_time) + ' seconds to try again.')\n",
    "                    time.sleep(sleep_time)\n",
    "                    sleep_time *= 2\n",
    "    print('########## END of collections. ##########')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting...\n",
      "Total deals (SKU, self and BI): 445631\n",
      "Blackword filter: 353510\n",
      "Only cluster category filter: 205735\n",
      "New users filter: 205735\n",
      "Penalty sellers filter 205735\n",
      "\n",
      "######### Generating 8 12 06 Spike Day Guide - Up to R$10 entre R$5 e R$10 #########\n",
      "Repeated items across microsite drop: 205735\n",
      "Collection with BI: 205735\n",
      "Price filter: 8288\n",
      "Category filter: 6198\n",
      "Max items filter: 450\n",
      "Applying score... 450\n",
      "Sorting by category... 450\n",
      "Creating rank column... 450\n",
      "Applying final columns... 450\n",
      "Creating collection file...\n",
      "Collection created.\n",
      "\n",
      "######### Generating 9 12 06 Spike Day Guide - Up to R$30 #########\n",
      "Repeated items across microsite drop: 205735\n",
      "Collection with BI: 205735\n",
      "Price filter: 58912\n",
      "Category filter: 47023\n",
      "Max items filter: 450\n",
      "Applying score... 450\n",
      "Sorting by category... 450\n",
      "Creating rank column... 450\n",
      "Applying final columns... 450\n",
      "Creating collection file...\n",
      "Collection created.\n",
      "\n",
      "######### Generating 10 12 06 Spike Day Guide - Up to R$50 #########\n",
      "Repeated items across microsite drop: 205735\n",
      "Collection with BI: 205735\n",
      "Price filter: 58712\n",
      "Category filter: 50277\n",
      "Max items filter: 450\n",
      "Applying score... 450\n",
      "Sorting by category... 450\n",
      "Creating rank column... 450\n",
      "Applying final columns... 450\n",
      "Creating collection file...\n",
      "Collection created.\n",
      "\n",
      "######### Generating 42 At Least 40 OFF - Fashion Clothes #########\n",
      "Repeated items across microsite drop: 205735\n",
      "Collection with BI: 205735\n",
      "Discount filter: 37411\n",
      "Category filter: 14184\n",
      "Max items filter: 450\n",
      "Applying score... 450\n",
      "Sorting by category... 450\n",
      "Creating rank column... 450\n",
      "Applying final columns... 450\n",
      "Creating collection file...\n",
      "Collection created.\n",
      "\n",
      "######### Generating 43 At Least 40 OFF - Shoes and Bags #########\n",
      "Repeated items across microsite drop: 205735\n",
      "Collection with BI: 205735\n",
      "Discount filter: 37411\n",
      "Category filter: 5167\n",
      "Max items filter: 450\n",
      "Applying score... 450\n",
      "Sorting by category... 450\n",
      "Creating rank column... 450\n",
      "Applying final columns... 450\n",
      "Creating collection file...\n",
      "Collection created.\n",
      "########## END of collections. ##########\n"
     ]
    }
   ],
   "source": [
    "engine_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cf3f97d741c99d1caf1e56efb900ab0626f8a3924a09a170b60febeb87130d0f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
